{"url": "https://api.github.com/repos/NVIDIAGameWorks/kaolin-wisp/releases/73567979", "assets_url": "https://api.github.com/repos/NVIDIAGameWorks/kaolin-wisp/releases/73567979/assets", "upload_url": "https://uploads.github.com/repos/NVIDIAGameWorks/kaolin-wisp/releases/73567979/assets{?name,label}", "html_url": "https://github.com/NVIDIAGameWorks/kaolin-wisp/releases/tag/v0.1.0", "id": 73567979, "author": {"login": "orperel", "id": 9556101, "node_id": "MDQ6VXNlcjk1NTYxMDE=", "avatar_url": "https://avatars.githubusercontent.com/u/9556101?v=4", "gravatar_id": "", "url": "https://api.github.com/users/orperel", "html_url": "https://github.com/orperel", "followers_url": "https://api.github.com/users/orperel/followers", "following_url": "https://api.github.com/users/orperel/following{/other_user}", "gists_url": "https://api.github.com/users/orperel/gists{/gist_id}", "starred_url": "https://api.github.com/users/orperel/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/orperel/subscriptions", "organizations_url": "https://api.github.com/users/orperel/orgs", "repos_url": "https://api.github.com/users/orperel/repos", "events_url": "https://api.github.com/users/orperel/events{/privacy}", "received_events_url": "https://api.github.com/users/orperel/received_events", "type": "User", "site_admin": false}, "node_id": "RE_kwDOHuEIPc4EYo7r", "tag_name": "v0.1.0", "target_commitish": "main", "name": "v0.1.0", "draft": false, "prerelease": false, "created_at": "2022-08-03T13:39:41Z", "published_at": "2022-08-03T18:08:34Z", "assets": [], "tarball_url": "https://api.github.com/repos/NVIDIAGameWorks/kaolin-wisp/tarball/v0.1.0", "zipball_url": "https://api.github.com/repos/NVIDIAGameWorks/kaolin-wisp/zipball/v0.1.0", "body": "# Highlights\r\nFirst kaolin-wisp release.\r\nSupports full optimization pipelines of neural radiance fields and signed distance functions.\r\nAlso includes an interactive renderer to visualize the optimization progress.\r\n\r\n# Features List\r\n\r\n## Core\r\n\r\n### Acceleration Structures\r\nAn Octree allows for fast location based queries and raymarching operations.\r\nOn NVIDIA RTX 3090, that brings NeRF training time down to anywhere between tens of seconds to single minutes for single objects like the bulldozer.\r\n(The exact performance is affected by other blocks in the neural pipeline: tracer, feature structure, etc..)\r\n\r\n### Feature Grids\r\nThe initial version of wisp is shipped with 4 types of feature grids:\r\n* Octree (from [Neural Geometric Level of Detail](https://nv-tlabs.github.io/nglod/))\r\n* Hash grid (from [Instant Neural Graphics Primitives](https://github.com/NVlabs/instant-ngp))\r\n* Triplane (from [Convolutional Occupancy Networks](https://github.com/autonomousvision/convolutional_occupancy_networks), [EG3D](https://nvlabs.github.io/eg3d/))\r\n* Codebook (from [VQAD](https://nv-tlabs.github.io/vqad/))\r\nThe hash grid is implemented as a CUDA kernel to further narrow the performance gap with the original NGP project.\r\n\r\n### Additional Building Blocks\r\nSupport for Positional Encoding (Fourier), torch MLP Decoders.\r\n\r\n### Neural Fields\r\n* Neural Fields can be composed and configured with the various building blocks: occupancy & feature structures, embedders, decoders and so forth.\r\n* Wisp is shipped with implementations for NeuralRadianceFields and NeuralSDFs.\r\n* New types of neural fields can be registered for research purposes.\r\n\r\n### Tracers\r\nThe tracers framework supports types of channels (i.e: rgba, sdf)\r\n2 implementations of differentiable ray tracers are included.\r\n* Radiance Fields\r\n* Sphere tracer for SDFs\r\nBoth tracers keep samples as packed tensors and use the octree to accelerated performance.\r\nRaymarching backed by the octree supports 2 modes of sampling along the ray:\r\n* `'voxel'` - fixed amount of samples will be generated per \"octree cell\"\r\n* `'ray'` - fixed amount of samples will be generated between the near / far planes of the camera.\r\n\r\n### Core Structures\r\n* `RenderBuffer` - smart pixel buffers used by tracers. Support custom types of `Channel`s and various blending and channel normalization modes.\r\n* `Ray` - batched ray packs for ray generation\r\n\r\n### Ray Generators\r\n* Ray generation uses kaolin's [Camera](https://kaolin.readthedocs.io/en/latest/modules/kaolin.render.camera.html) module.\r\n* Default ray generators for perspective and ortho cameras are available.\r\n\r\n### Ops\r\nA toolkit for loading, processing and evaluation of various modalities is included in this version (including images, meshes, sdfs and kaolin's [Structured Point Clouds](https://kaolin.readthedocs.io/en/latest/notes/spc_summary.html).\r\n\r\n### Data Loaders\r\nwisp ships with data loaders support for:\r\n* Multiview images: NeRF standard dataset format, including extensions to the format introduced by [Instant Neural Graphics Primitives](https://github.com/NVlabs/instant-ngp)).\r\n* Multiview images: [RTMV dataset ](http://www.cs.umd.edu/~mmeshry/projects/rtmv/).\r\n* SDFs: OBJs + online samples (usually done once in the beginning of optimization)\r\n\r\n\r\n### Training\r\n2 trainers are currently supported (for NeRF and SDFs).\r\nTrainers can run with or without the interactive renderer.\r\n\r\n\r\n## Interactive Renderer\r\n\r\nWisp includes an interactive renderer with flexible support for new types of neural objects.\r\nThe renderer was built in mind to support future neural pipelines which may not yet exist.\r\nDependencies: pycuda, glumpy, glfw, imgui.\r\n\r\n### Scene Graph & Renderers\r\n* The renderer core fully supports neural fields and tracers currently available in wisp core (NeRF, SDFs traced via the packed tracers).\r\n* Neural fields are implemented as standalone renderers which produce a RenderBuffer.\r\nThe renderer core supports multiple shape types by blending such buffers.\r\n* All objects are stored inside a scene graph. The scene graph can be manipulated to toggle objects visibility and adjust properties.\r\n\r\n### Debug Visualizations\r\n* Line primitives can be drawn on the canvas to display additional layers of information (i.e. Octree occupancy).\r\n* The optimization runs in parallel to the renderer, allowing for ad-hoc interaction with the optimized scene.\r\n\r\n### Canvas Modes\r\n* The canvas supports visualization of custom channels (rgb, depth..)\r\n* Camera can switch between perspective and ortho\r\n* Camera controllers: First person, Trackball, Turntable\r\n\r\n### Custom Apps & Gui\r\n* Wisp apps are highly customizable: the gui and canvas gizmos can be configured to display specific menus / canvas transients (such as the world grid).\r\n* The gui can be extended with new types of widgets.\r\n\r\n\r\n**Full Changelog**: https://github.com/NVIDIAGameWorks/kaolin-wisp/commits/v0.1.0"}
