{"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/77238551", "assets_url": "https://api.github.com/repos/stanfordnlp/stanza/releases/77238551/assets", "upload_url": "https://uploads.github.com/repos/stanfordnlp/stanza/releases/77238551/assets{?name,label}", "html_url": "https://github.com/stanfordnlp/stanza/releases/tag/v1.4.2", "id": 77238551, "author": {"login": "AngledLuffa", "id": 3411033, "node_id": "MDQ6VXNlcjM0MTEwMzM=", "avatar_url": "https://avatars.githubusercontent.com/u/3411033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AngledLuffa", "html_url": "https://github.com/AngledLuffa", "followers_url": "https://api.github.com/users/AngledLuffa/followers", "following_url": "https://api.github.com/users/AngledLuffa/following{/other_user}", "gists_url": "https://api.github.com/users/AngledLuffa/gists{/gist_id}", "starred_url": "https://api.github.com/users/AngledLuffa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AngledLuffa/subscriptions", "organizations_url": "https://api.github.com/users/AngledLuffa/orgs", "repos_url": "https://api.github.com/users/AngledLuffa/repos", "events_url": "https://api.github.com/users/AngledLuffa/events{/privacy}", "received_events_url": "https://api.github.com/users/AngledLuffa/received_events", "type": "User", "site_admin": false}, "node_id": "RE_kwDOBj_0V84EmpEX", "tag_name": "v1.4.2", "target_commitish": "main", "name": "Stanza v1.4.2", "draft": false, "prerelease": false, "created_at": "2022-09-15T06:04:09Z", "published_at": "2022-09-15T05:47:38Z", "assets": [], "tarball_url": "https://api.github.com/repos/stanfordnlp/stanza/tarball/v1.4.2", "zipball_url": "https://api.github.com/repos/stanfordnlp/stanza/zipball/v1.4.2", "body": "# Stanza v1.4.2: Minor version bump to improve (python) dependencies\r\n\r\n- Pipeline cache in Multilingual is a single OrderedDict\r\nhttps://github.com/stanfordnlp/stanza/issues/1115#issuecomment-1239759362\r\nhttps://github.com/stanfordnlp/stanza/commit/ba3f64d5f571b1dc70121551364fc89d103ca1cd\r\n\r\n- Don't require `pytest` for all installations unless needed for testing\r\nhttps://github.com/stanfordnlp/stanza/issues/1120\r\nhttps://github.com/stanfordnlp/stanza/commit/8c1d9d80e2e12729f60f05b81e88e113fbdd3482\r\n\r\n- hide SiLU and Minh imports if the version of torch installed doesn't have those nonlinearities\r\nhttps://github.com/stanfordnlp/stanza/issues/1120\r\nhttps://github.com/stanfordnlp/stanza/commit/6a90ad4bacf923c88438da53219c48355b847ed3\r\n\r\n- Reorder & normalize installations in setup.py\r\nhttps://github.com/stanfordnlp/stanza/pull/1124\r\n", "reactions": {"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/77238551/reactions", "total_count": 1, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 1, "rocket": 0, "eyes": 0}}
{"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/77160254", "assets_url": "https://api.github.com/repos/stanfordnlp/stanza/releases/77160254/assets", "upload_url": "https://uploads.github.com/repos/stanfordnlp/stanza/releases/77160254/assets{?name,label}", "html_url": "https://github.com/stanfordnlp/stanza/releases/tag/v1.4.1", "id": 77160254, "author": {"login": "AngledLuffa", "id": 3411033, "node_id": "MDQ6VXNlcjM0MTEwMzM=", "avatar_url": "https://avatars.githubusercontent.com/u/3411033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AngledLuffa", "html_url": "https://github.com/AngledLuffa", "followers_url": "https://api.github.com/users/AngledLuffa/followers", "following_url": "https://api.github.com/users/AngledLuffa/following{/other_user}", "gists_url": "https://api.github.com/users/AngledLuffa/gists{/gist_id}", "starred_url": "https://api.github.com/users/AngledLuffa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AngledLuffa/subscriptions", "organizations_url": "https://api.github.com/users/AngledLuffa/orgs", "repos_url": "https://api.github.com/users/AngledLuffa/repos", "events_url": "https://api.github.com/users/AngledLuffa/events{/privacy}", "received_events_url": "https://api.github.com/users/AngledLuffa/received_events", "type": "User", "site_admin": false}, "node_id": "RE_kwDOBj_0V84EmV8-", "tag_name": "v1.4.1", "target_commitish": "main", "name": "Stanza v1.4.1", "draft": false, "prerelease": false, "created_at": "2022-09-14T02:52:32Z", "published_at": "2022-09-14T16:41:36Z", "assets": [], "tarball_url": "https://api.github.com/repos/stanfordnlp/stanza/tarball/v1.4.1", "zipball_url": "https://api.github.com/repos/stanfordnlp/stanza/zipball/v1.4.1", "body": "# Stanza v1.4.1: Improvements to pos, conparse, and sentiment, jupyter visualization, and wider language coverage\r\n\r\n## Overview\r\n\r\nWe improve the quality of the POS, constituency, and sentiment models, add an integration to displaCy, and add new models for a variety of languages.\r\n\r\n## New NER models\r\n\r\n- New Polish NER model based on NKJP from Karol Saputa and ryszardtuora\r\nhttps://github.com/stanfordnlp/stanza/issues/1070\r\nhttps://github.com/stanfordnlp/stanza/pull/1110\r\n\r\n- Make GermEval2014 the default German NER model, including an optional Bert version\r\nhttps://github.com/stanfordnlp/stanza/issues/1018\r\nhttps://github.com/stanfordnlp/stanza/pull/1022\r\n\r\n- Japanese conversion of GSD by Megagon\r\nhttps://github.com/stanfordnlp/stanza/pull/1038\r\n\r\n- Marathi NER dataset from L3Cube.  Includes a Sentiment model as well\r\nhttps://github.com/stanfordnlp/stanza/pull/1043\r\n\r\n- Thai conversion of LST20\r\nhttps://github.com/stanfordnlp/stanza/commit/555fc0342decad70f36f501a7ea1e29fa0c5b317\r\n\r\n- Kazakh conversion of KazNERD\r\nhttps://github.com/stanfordnlp/stanza/pull/1091/commits/de6cd25c2e5b936bc4ad2764b7b67751d0b862d7\r\n\r\n## Other new models\r\n\r\n- Sentiment conversion of Tass2020 for Spanish\r\nhttps://github.com/stanfordnlp/stanza/pull/1104\r\n\r\n- VIT constituency dataset for Italian\r\nhttps://github.com/stanfordnlp/stanza/pull/1091/commits/149f1440dc32d47fbabcc498cfcd316e53aca0c6\r\n... and many subsequent updates\r\n\r\n- Combined UD models for Hebrew\r\nhttps://github.com/stanfordnlp/stanza/issues/1109\r\nhttps://github.com/stanfordnlp/stanza/commit/e4fcf003feb984f535371fb91c9e380dd187fd12\r\n\r\n- For UD models with small train dataset & larger test dataset, flip the datasets\r\nUD_Buryat-BDT UD_Kazakh-KTB UD_Kurmanji-MG UD_Ligurian-GLT UD_Upper_Sorbian-UFAL\r\nhttps://github.com/stanfordnlp/stanza/issues/1030\r\nhttps://github.com/stanfordnlp/stanza/commit/9618d60d63c49ec1bfff7416e3f1ad87300c7073\r\n\r\n- Spanish conparse model from multiple sources - AnCora, LDC-NW, LDC-DF\r\nhttps://github.com/stanfordnlp/stanza/commit/47740c6252a6717f12ef1fde875cf19fa1cd67cc\r\n\r\n## Model improvements\r\n\r\n- Pretrained charlm integrated into POS.  Gives a small to decent gain for most languages without much additional cost\r\nhttps://github.com/stanfordnlp/stanza/pull/1086\r\n\r\n- Pretrained charlm integrated into Sentiment.  Improves English, others not so much\r\nhttps://github.com/stanfordnlp/stanza/pull/1025\r\n\r\n- LSTM, 2d maxpool as optional items in the Sentiment\r\nfrom the paper `Text Classification Improved by Integrating Bidirectional LSTM with Two-dimensional Max Pooling`\r\nhttps://github.com/stanfordnlp/stanza/pull/1098\r\n\r\n- First learn with AdaDelta, then with another optimizer in conparse training.  Very helpful\r\nhttps://github.com/stanfordnlp/stanza/commit/b1d10d3bdd892c7f68d2da7f4ba68a6ae3087f52\r\n\r\n- Grad clipping in conparse training\r\nhttps://github.com/stanfordnlp/stanza/commit/365066add019096332bcba0da4a626f68b70d303\r\n\r\n## Pipeline interface improvements\r\n\r\n- GPU memory savings: charlm reused between different processors in the same pipeline\r\nhttps://github.com/stanfordnlp/stanza/pull/1028\r\n\r\n- Word vectors not saved in the NER models.  Saves bandwidth & disk space\r\nhttps://github.com/stanfordnlp/stanza/pull/1033\r\n\r\n- Functions to return tagsets for NER and conparse models\r\nhttps://github.com/stanfordnlp/stanza/issues/1066\r\nhttps://github.com/stanfordnlp/stanza/pull/1073\r\nhttps://github.com/stanfordnlp/stanza/commit/36b84db71f19e37b36119e2ec63f89d1e509acb0\r\nhttps://github.com/stanfordnlp/stanza/commit/2db43c834bc8adbb8b096cf135f0fab8b8d886cb\r\n\r\n- displaCy integration with NER and dependency trees\r\nhttps://github.com/stanfordnlp/stanza/commit/20714137d81e5e63d2bcee420b22c4fd2a871306\r\n\r\n## Bugfixes\r\n\r\n- Fix that it takes forever to tokenize a single long token (catastrophic backtracking in regex)\r\nTY to Sk Adnan Hassan (VT) and Zainab Aamir (Stony Brook)\r\nhttps://github.com/stanfordnlp/stanza/pull/1056\r\n\r\n- Starting a new corenlp client w/o server shouldn't wait for the server to be available\r\nTY to Mariano Crosetti\r\nhttps://github.com/stanfordnlp/stanza/issues/1059\r\nhttps://github.com/stanfordnlp/stanza/pull/1061\r\n\r\n- Read raw glove word vectors (they have no header information)\r\nhttps://github.com/stanfordnlp/stanza/pull/1074\r\n\r\n- Ensure that illegal languages are not chosen by the LangID model\r\nhttps://github.com/stanfordnlp/stanza/issues/1076\r\nhttps://github.com/stanfordnlp/stanza/pull/1077\r\n\r\n- Fix cache in Multilingual pipeline\r\nhttps://github.com/stanfordnlp/stanza/issues/1115\r\nhttps://github.com/stanfordnlp/stanza/commit/cdf18d8b19c92b0cfbbf987e82b0080ea7b4db32\r\n\r\n- Fix loading of previously unseen languages in Multilingual pipeline\r\nhttps://github.com/stanfordnlp/stanza/issues/1101\r\nhttps://github.com/stanfordnlp/stanza/commit/e551ebe60a4d818bc5ba8880dda741cc8bd1aed7\r\n\r\n- Fix that conparse would occasionally train to NaN early in the training\r\nhttps://github.com/stanfordnlp/stanza/commit/c4d785729e42ac90f298e0ef4ab487d14fa35591\r\n\r\n## Improved training tools\r\n\r\n- W&B integration for all models: can be activated with --wandb flag in the training scripts\r\nhttps://github.com/stanfordnlp/stanza/pull/1040\r\n\r\n- New webpages for building charlm, NER, and Sentiment\r\nhttps://stanfordnlp.github.io/stanza/new_language_charlm.html\r\nhttps://stanfordnlp.github.io/stanza/new_language_ner.html\r\nhttps://stanfordnlp.github.io/stanza/new_language_sentiment.html\r\n\r\n- Script to download Oscar 2019 data for charlm from HF (requires `datasets` module)\r\nhttps://github.com/stanfordnlp/stanza/pull/1014\r\n\r\n- Unify sentiment training into a Python script, replacing the old shell script\r\nhttps://github.com/stanfordnlp/stanza/pull/1021\r\nhttps://github.com/stanfordnlp/stanza/pull/1023\r\n\r\n- Convert sentiment to use .json inputs.  In particular, this helps with languages with spaces in words such as Vietnamese\r\nhttps://github.com/stanfordnlp/stanza/pull/1024\r\n\r\n- Slightly faster charlm training\r\nhttps://github.com/stanfordnlp/stanza/pull/1026\r\n\r\n- Data conversion of WikiNER generalized for retraining / add new WikiNER models\r\nhttps://github.com/stanfordnlp/stanza/pull/1039\r\n\r\n- XPOS factory now determined at start of POS training.  Makes addition of new languages easier\r\nhttps://github.com/stanfordnlp/stanza/pull/1082\r\n\r\n- Checkpointing and continued training for charlm, conparse, sentiment\r\nhttps://github.com/stanfordnlp/stanza/pull/1090\r\nhttps://github.com/stanfordnlp/stanza/commit/0e6de808eacf14cd64622415eeaeeac2d60faab2\r\nhttps://github.com/stanfordnlp/stanza/commit/e5793c9dd5359f7e8f4fe82bf318a2f8fd190f54\r\n\r\n- Option to write the results of a NER model to a file\r\nhttps://github.com/stanfordnlp/stanza/pull/1108\r\n\r\n- Add fake dependencies to a conllu formatted dataset for better integration with evaluation tools\r\nhttps://github.com/stanfordnlp/stanza/commit/6544ef3fa5e4f1b7f06dbcc5521fbf9b1264197a\r\n\r\n- Convert an AMT NER result to Stanza .json\r\nhttps://github.com/stanfordnlp/stanza/commit/cfa7e496ca7c7662478e03c5565e1b2b2c026fad\r\n\r\n- Add a ton of language codes, including 3 letter codes for languages we generally treat as 2 letters\r\nhttps://github.com/stanfordnlp/stanza/commit/5a5e9187f81bd76fcd84ad713b51215b64234986\r\nhttps://github.com/stanfordnlp/stanza/commit/b32a98e477e9972737ad64deea0bda8d6cebb4ec and others\r\n", "discussion_url": "https://github.com/stanfordnlp/stanza/discussions/1121", "reactions": {"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/77160254/reactions", "total_count": 5, "+1": 0, "-1": 0, "laugh": 0, "hooray": 1, "confused": 0, "heart": 4, "rocket": 0, "eyes": 0}}
{"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/58308589", "assets_url": "https://api.github.com/repos/stanfordnlp/stanza/releases/58308589/assets", "upload_url": "https://uploads.github.com/repos/stanfordnlp/stanza/releases/58308589/assets{?name,label}", "html_url": "https://github.com/stanfordnlp/stanza/releases/tag/v1.4.0", "id": 58308589, "author": {"login": "AngledLuffa", "id": 3411033, "node_id": "MDQ6VXNlcjM0MTEwMzM=", "avatar_url": "https://avatars.githubusercontent.com/u/3411033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AngledLuffa", "html_url": "https://github.com/AngledLuffa", "followers_url": "https://api.github.com/users/AngledLuffa/followers", "following_url": "https://api.github.com/users/AngledLuffa/following{/other_user}", "gists_url": "https://api.github.com/users/AngledLuffa/gists{/gist_id}", "starred_url": "https://api.github.com/users/AngledLuffa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AngledLuffa/subscriptions", "organizations_url": "https://api.github.com/users/AngledLuffa/orgs", "repos_url": "https://api.github.com/users/AngledLuffa/repos", "events_url": "https://api.github.com/users/AngledLuffa/events{/privacy}", "received_events_url": "https://api.github.com/users/AngledLuffa/received_events", "type": "User", "site_admin": false}, "node_id": "RE_kwDOBj_0V84Debft", "tag_name": "v1.4.0", "target_commitish": "main", "name": "Stanza v1.4.0", "draft": false, "prerelease": false, "created_at": "2022-04-23T04:36:46Z", "published_at": "2022-04-23T06:01:01Z", "assets": [], "tarball_url": "https://api.github.com/repos/stanfordnlp/stanza/tarball/v1.4.0", "zipball_url": "https://api.github.com/repos/stanfordnlp/stanza/zipball/v1.4.0", "body": "# Stanza v1.4.0: Transformer integration to NER and conparse\r\n\r\n## Overview\r\n\r\nAs part of the new Stanza release, we integrate transformer inputs to the NER and conparse modules.  In addition, we now support several additional languages for NER and conparse.\r\n\r\n## Pipeline interface improvements\r\n\r\n- Download resources.json and models into temp dirs first to avoid race conditions between multiple processors\r\nhttps://github.com/stanfordnlp/stanza/issues/213\r\nhttps://github.com/stanfordnlp/stanza/pull/1001\r\n\r\n- Download models for Pipelines automatically, without needing to call `stanza.download(...)`\r\nhttps://github.com/stanfordnlp/stanza/issues/486\r\nhttps://github.com/stanfordnlp/stanza/pull/943\r\n\r\n- Add ability to turn off downloads\r\nhttps://github.com/stanfordnlp/stanza/commit/68455d895986357a2c1f496e52c4e59ee0feb165\r\n\r\n- Add a new interface where both processors and package can be set\r\nhttps://github.com/stanfordnlp/stanza/issues/917\r\nhttps://github.com/stanfordnlp/stanza/commit/f37042924b7665bbaf006b02dcbf8904d71931a1\r\n\r\n- When using pretokenized tokens, get character offsets from text if available\r\nhttps://github.com/stanfordnlp/stanza/issues/967\r\nhttps://github.com/stanfordnlp/stanza/pull/975\r\n\r\n- If Bert or other transformers are used, cache the models rather than loading multiple times\r\nhttps://github.com/stanfordnlp/stanza/pull/980\r\n\r\n- Allow for disabling processors on individual runs of a pipeline\r\nhttps://github.com/stanfordnlp/stanza/issues/945\r\nhttps://github.com/stanfordnlp/stanza/pull/947\r\n\r\n## Other general improvements\r\n\r\n- Add # text and # sent_id to conll output\r\nhttps://github.com/stanfordnlp/stanza/discussions/918\r\nhttps://github.com/stanfordnlp/stanza/pull/983\r\nhttps://github.com/stanfordnlp/stanza/pull/995\r\n\r\n- Add ner to the token conll output\r\nhttps://github.com/stanfordnlp/stanza/discussions/993\r\nhttps://github.com/stanfordnlp/stanza/pull/996\r\n\r\n- Fix missing Slovak MWT model\r\nhttps://github.com/stanfordnlp/stanza/issues/971\r\nhttps://github.com/stanfordnlp/stanza/commit/5aa19ec2e6bc610576bc12d226d6f247a21dbd75\r\n\r\n- Upgrades to EN, IT, and Indonesian models\r\nhttps://github.com/stanfordnlp/stanza/issues/1003\r\nhttps://github.com/stanfordnlp/stanza/pull/1008\r\nIT improvements with the help of @attardi and @msimi\r\n\r\n- Fix improper tokenization of Chinese text with leading whitespace\r\nhttps://github.com/stanfordnlp/stanza/issues/920\r\nhttps://github.com/stanfordnlp/stanza/pull/924\r\n\r\n- Check if a CoreNLP model exists before downloading it (thank you @interNULL)\r\nhttps://github.com/stanfordnlp/stanza/pull/965\r\n\r\n- Convert the run_charlm script to python\r\nhttps://github.com/stanfordnlp/stanza/pull/942\r\n\r\n- Typing and lint fixes (thank you @asears)\r\nhttps://github.com/stanfordnlp/stanza/pull/833\r\nhttps://github.com/stanfordnlp/stanza/pull/856\r\n\r\n- stanza-train examples now compatible with the python training scripts\r\nhttps://github.com/stanfordnlp/stanza/issues/896\r\n\r\n## NER features\r\n\r\n- Bert integration (not by default, thank you @vythaihn)\r\nhttps://github.com/stanfordnlp/stanza/pull/976\r\n\r\n- Swedish model (thank you @EmilStenstrom)\r\nhttps://github.com/stanfordnlp/stanza/issues/912\r\nhttps://github.com/stanfordnlp/stanza/pull/857\r\n\r\n- Persian model\r\nhttps://github.com/stanfordnlp/stanza/issues/797\r\n\r\n- Danish model\r\nhttps://github.com/stanfordnlp/stanza/pull/910/commits/3783cc494ee8c6b6d062c4d652a428a04a4ee839\r\n\r\n- Norwegian model (both NB and NN)\r\nhttps://github.com/stanfordnlp/stanza/pull/910/commits/31fa23e5239b10edca8ecea46e2114f9cc7b031d\r\n\r\n- Use updated Ukrainian data (thank you @gawy)\r\nhttps://github.com/stanfordnlp/stanza/pull/873\r\n\r\n- Myanmar model (thank you UCSY)\r\nhttps://github.com/stanfordnlp/stanza/pull/845\r\n\r\n- Training improvements for finetuning models\r\nhttps://github.com/stanfordnlp/stanza/issues/788\r\nhttps://github.com/stanfordnlp/stanza/pull/791\r\n\r\n- Fix inconsistencies in B/S/I/E tags\r\nhttps://github.com/stanfordnlp/stanza/issues/928#issuecomment-1027987531\r\nhttps://github.com/stanfordnlp/stanza/pull/961\r\n\r\n- Add an option for multiple NER models at the same time, merging the results together\r\nhttps://github.com/stanfordnlp/stanza/issues/928\r\nhttps://github.com/stanfordnlp/stanza/pull/955\r\n\r\n## Constituency parser\r\n\r\n- Dynamic oracle (improves accuracy a bit)\r\nhttps://github.com/stanfordnlp/stanza/pull/866\r\n\r\n- Missing tags now okay in the parser\r\nhttps://github.com/stanfordnlp/stanza/issues/862\r\nhttps://github.com/stanfordnlp/stanza/commit/04dbf4f65e417a2ceb19897ab62c4cf293187c0b\r\n\r\n- bugfix of () not being escaped when output in a tree\r\nhttps://github.com/stanfordnlp/stanza/commit/eaf134ca699aca158dc6e706878037a20bc8cbd4\r\n\r\n- charlm integration by default\r\nhttps://github.com/stanfordnlp/stanza/pull/799\r\n\r\n- Bert integration (not the default model) (thank you @vythaihn and @hungbui0411)\r\nhttps://github.com/stanfordnlp/stanza/commit/05a0b04ee6dd701ca1c7c60197be62d4c13b17b6\r\nhttps://github.com/stanfordnlp/stanza/commit/0bbe8d10f895560a2bf16f542d2e3586d5d45b7e\r\n\r\n- Preemptive bugfix for incompatible devices from @zhaochaocs\r\nhttps://github.com/stanfordnlp/stanza/issues/989\r\nhttps://github.com/stanfordnlp/stanza/pull/1002\r\n\r\n- New models:\r\nDA, based on [Arboretum](http://catalog.elra.info/en-us/repository/browse/ELRA-W0084/)\r\n IT, based on the [Turin treebank](http://www.di.unito.it/~tutreeb/treebanks.html)\r\nJA, based on [ALT](https://www2.nict.go.jp/astrec-att/member/mutiyama/ALT/)\r\nPT, based on [Cintil](https://catalogue.elra.info/en-us/repository/browse/ELRA-W0055/)\r\nTR, based on [Starlang](https://www.researchgate.net/publication/344829282_Creating_A_Syntactically_Felicitous_Constituency_Treebank_For_Turkish)\r\nZH, based on CTB7\r\n\r\n", "discussion_url": "https://github.com/stanfordnlp/stanza/discussions/1013", "mentions_count": 9}
{"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/50863402", "assets_url": "https://api.github.com/repos/stanfordnlp/stanza/releases/50863402/assets", "upload_url": "https://uploads.github.com/repos/stanfordnlp/stanza/releases/50863402/assets{?name,label}", "html_url": "https://github.com/stanfordnlp/stanza/releases/tag/v1.3.0", "id": 50863402, "author": {"login": "AngledLuffa", "id": 3411033, "node_id": "MDQ6VXNlcjM0MTEwMzM=", "avatar_url": "https://avatars.githubusercontent.com/u/3411033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AngledLuffa", "html_url": "https://github.com/AngledLuffa", "followers_url": "https://api.github.com/users/AngledLuffa/followers", "following_url": "https://api.github.com/users/AngledLuffa/following{/other_user}", "gists_url": "https://api.github.com/users/AngledLuffa/gists{/gist_id}", "starred_url": "https://api.github.com/users/AngledLuffa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AngledLuffa/subscriptions", "organizations_url": "https://api.github.com/users/AngledLuffa/orgs", "repos_url": "https://api.github.com/users/AngledLuffa/repos", "events_url": "https://api.github.com/users/AngledLuffa/events{/privacy}", "received_events_url": "https://api.github.com/users/AngledLuffa/received_events", "type": "User", "site_admin": false}, "node_id": "RE_kwDOBj_0V84DCB0q", "tag_name": "v1.3.0", "target_commitish": "main", "name": "Stanza 1.3.0: LangID and Constituency Parser", "draft": false, "prerelease": false, "created_at": "2021-10-05T02:15:34Z", "published_at": "2021-10-06T06:28:19Z", "assets": [], "tarball_url": "https://api.github.com/repos/stanfordnlp/stanza/tarball/v1.3.0", "zipball_url": "https://api.github.com/repos/stanfordnlp/stanza/zipball/v1.3.0", "body": "# Overview\r\n\r\nStanza 1.3.0 introduces a language id model, a constituency parser, a dictionary in the tokenizer, and some additional features and bugfixes.\r\n\r\n## New features\r\n\r\n- **Langid model and multilingual pipeline**\r\nBased on \"A reproduction of Apple's bi-directional LSTM models for language identification in short strings.\" by Toftrup et al 2021\r\n(https://github.com/stanfordnlp/stanza/commit/154b0e8e59d3276744ae0c8ea56dc226f777fba8)\r\n\r\n- **Constituency parser**\r\nBased on \"In-Order Transition-based Constituent Parsing\" by Jiangming Liu and Yue Zhang.  Currently an `en_wsj` model available, with more to come.\r\n(https://github.com/stanfordnlp/stanza/commit/90318023432d584c62986123ef414a1fa93683ca)\r\n\r\n- **Evalb interface to CoreNLP**\r\nUseful for evaluating the parser - requires CoreNLP 4.3.0 or later\r\n\r\n- **Dictonary tokenizer feature**\r\nNoticeably improved performance for ZH, VI, TH\r\n(https://github.com/stanfordnlp/stanza/pull/776)\r\n\r\n## Bugfixes / Reliability\r\n\r\n- **HuggingFace integration**\r\nNo more git issues complaining about unavailable models!  (Hopefully)\r\n(https://github.com/stanfordnlp/stanza/commit/f7af5049568f81a716106fee5403d339ca246f38)\r\n\r\n- **Sentiment processor crashes on certain inputs**\r\n(issue https://github.com/stanfordnlp/stanza/issues/804, fixed by https://github.com/stanfordnlp/stanza/commit/e232f67f3850a32a1b4f3a99e9eb4f5c5580c019)\r\n"}
{"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/47569987", "assets_url": "https://api.github.com/repos/stanfordnlp/stanza/releases/47569987/assets", "upload_url": "https://uploads.github.com/repos/stanfordnlp/stanza/releases/47569987/assets{?name,label}", "html_url": "https://github.com/stanfordnlp/stanza/releases/tag/v1.2.3", "id": 47569987, "author": {"login": "AngledLuffa", "id": 3411033, "node_id": "MDQ6VXNlcjM0MTEwMzM=", "avatar_url": "https://avatars.githubusercontent.com/u/3411033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AngledLuffa", "html_url": "https://github.com/AngledLuffa", "followers_url": "https://api.github.com/users/AngledLuffa/followers", "following_url": "https://api.github.com/users/AngledLuffa/following{/other_user}", "gists_url": "https://api.github.com/users/AngledLuffa/gists{/gist_id}", "starred_url": "https://api.github.com/users/AngledLuffa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AngledLuffa/subscriptions", "organizations_url": "https://api.github.com/users/AngledLuffa/orgs", "repos_url": "https://api.github.com/users/AngledLuffa/repos", "events_url": "https://api.github.com/users/AngledLuffa/events{/privacy}", "received_events_url": "https://api.github.com/users/AngledLuffa/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTQ3NTY5OTg3", "tag_name": "v1.2.3", "target_commitish": "main", "name": "Stanza v1.2.3: Two new NER models and some minor bugfixes", "draft": false, "prerelease": false, "created_at": "2021-08-09T23:11:56Z", "published_at": "2021-08-09T23:12:42Z", "assets": [], "tarball_url": "https://api.github.com/repos/stanfordnlp/stanza/tarball/v1.2.3", "zipball_url": "https://api.github.com/repos/stanfordnlp/stanza/zipball/v1.2.3", "body": "# Overview\r\n\r\nIn anticipation of a larger release with some new features, we make a small update to fix some existing bugs and add two more NER models.\r\n\r\n## Bugfixes\r\n\r\n- **Sentiment models would crash on no text** (issue https://github.com/stanfordnlp/stanza/issues/769, fixed by https://github.com/stanfordnlp/stanza/pull/781/commits/47889e3043c27f9c5abd9913016929f1857de7bf)\r\n\r\n- **Java processes as a context were not properly closed** (https://github.com/stanfordnlp/stanza/pull/781/commits/a39d2ff6801a23aa73add1f710d809a9c0a793b1)\r\n\r\n## Interface improvements\r\n\r\n- **Downloading tokenize now downloads mwt for languages which require it** (issue https://github.com/stanfordnlp/stanza/issues/774, fixed by https://github.com/stanfordnlp/stanza/pull/777, from davidrft)\r\n\r\n- **NER model can finetune and save to/from different filenames** (https://github.com/stanfordnlp/stanza/pull/781/commits/0714a0134f0af6ef486b49ce934f894536e31d43)\r\n\r\n- **NER model now displays a confusion matrix at the end of training** (https://github.com/stanfordnlp/stanza/pull/781/commits/9bbd3f712f97cb2702a0852e1c353d4d54b4b33b)\r\n\r\n## NER models\r\n\r\n- **Afrikaans, trained in NCHLT** (https://github.com/stanfordnlp/stanza/pull/781/commits/6f1f04b6d674691cf9932d780da436063ebd3381)\r\n\r\n- **Italian, trained on a model from FBK** (https://github.com/stanfordnlp/stanza/pull/781/commits/d9a361fd7f13105b68569fddeab650ea9bd04b7f)\r\n\r\n"}
{"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/44814871", "assets_url": "https://api.github.com/repos/stanfordnlp/stanza/releases/44814871/assets", "upload_url": "https://uploads.github.com/repos/stanfordnlp/stanza/releases/44814871/assets{?name,label}", "html_url": "https://github.com/stanfordnlp/stanza/releases/tag/v1.2.2", "id": 44814871, "author": {"login": "AngledLuffa", "id": 3411033, "node_id": "MDQ6VXNlcjM0MTEwMzM=", "avatar_url": "https://avatars.githubusercontent.com/u/3411033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AngledLuffa", "html_url": "https://github.com/AngledLuffa", "followers_url": "https://api.github.com/users/AngledLuffa/followers", "following_url": "https://api.github.com/users/AngledLuffa/following{/other_user}", "gists_url": "https://api.github.com/users/AngledLuffa/gists{/gist_id}", "starred_url": "https://api.github.com/users/AngledLuffa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AngledLuffa/subscriptions", "organizations_url": "https://api.github.com/users/AngledLuffa/orgs", "repos_url": "https://api.github.com/users/AngledLuffa/repos", "events_url": "https://api.github.com/users/AngledLuffa/events{/privacy}", "received_events_url": "https://api.github.com/users/AngledLuffa/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTQ0ODE0ODcx", "tag_name": "v1.2.2", "target_commitish": "main", "name": "Stanza v1.2.2", "draft": false, "prerelease": false, "created_at": "2021-07-13T04:49:50Z", "published_at": "2021-07-15T18:49:01Z", "assets": [], "tarball_url": "https://api.github.com/repos/stanfordnlp/stanza/tarball/v1.2.2", "zipball_url": "https://api.github.com/repos/stanfordnlp/stanza/zipball/v1.2.2", "body": "# Overview\r\n\r\nA regression in NER results occurred in 1.2.1 when fixing a bug in VI models based around spaces.\r\n\r\n## Bugfixes\r\n\r\n- **Fix Sentiment not loading correctly on Windows because of pickling issue** (https://github.com/stanfordnlp/stanza/pull/742) (thanks to @BramVanroy)\r\n\r\n- **Fix NER bulk process not filling out data structures as expected** (https://github.com/stanfordnlp/stanza/issues/721) (https://github.com/stanfordnlp/stanza/pull/722)\r\n\r\n- **Fix NER space issue causing a performance regression** (https://github.com/stanfordnlp/stanza/issues/739) (https://github.com/stanfordnlp/stanza/pull/732)\r\n\r\n## Interface improvements\r\n\r\n- **Add an NER run script** (https://github.com/stanfordnlp/stanza/pull/738)\r\n", "reactions": {"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/44814871/reactions", "total_count": 16, "+1": 12, "-1": 0, "laugh": 0, "hooray": 4, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}}
{"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/39087456", "assets_url": "https://api.github.com/repos/stanfordnlp/stanza/releases/39087456/assets", "upload_url": "https://uploads.github.com/repos/stanfordnlp/stanza/releases/39087456/assets{?name,label}", "html_url": "https://github.com/stanfordnlp/stanza/releases/tag/v1.2.1", "id": 39087456, "author": {"login": "AngledLuffa", "id": 3411033, "node_id": "MDQ6VXNlcjM0MTEwMzM=", "avatar_url": "https://avatars.githubusercontent.com/u/3411033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AngledLuffa", "html_url": "https://github.com/AngledLuffa", "followers_url": "https://api.github.com/users/AngledLuffa/followers", "following_url": "https://api.github.com/users/AngledLuffa/following{/other_user}", "gists_url": "https://api.github.com/users/AngledLuffa/gists{/gist_id}", "starred_url": "https://api.github.com/users/AngledLuffa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AngledLuffa/subscriptions", "organizations_url": "https://api.github.com/users/AngledLuffa/orgs", "repos_url": "https://api.github.com/users/AngledLuffa/repos", "events_url": "https://api.github.com/users/AngledLuffa/events{/privacy}", "received_events_url": "https://api.github.com/users/AngledLuffa/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTM5MDg3NDU2", "tag_name": "v1.2.1", "target_commitish": "main", "name": "Stanza v1.2.1", "draft": false, "prerelease": false, "created_at": "2021-06-08T22:32:56Z", "published_at": "2021-06-17T17:12:31Z", "assets": [], "tarball_url": "https://api.github.com/repos/stanfordnlp/stanza/tarball/v1.2.1", "zipball_url": "https://api.github.com/repos/stanfordnlp/stanza/zipball/v1.2.1", "body": "# Overview\r\n\r\nAll models other than NER and Sentiment were retrained with the new UD 2.8 release.  All of the updates include the data augmentation fixes applied in 1.2.0, along with new augmentations tokenization issues and end-of-sentence issues.  This release also features various enhancements, bug fixes, and performance improvements, along with 4 new NER models.\r\n\r\n## Model improvements\r\n\r\n- **Add Bulgarian, Finnish, Hungarian, Vietnamese NER models**\r\n  - The Bulgarian model is trained on BSNLP 2019 data.\r\n  - The Finnish model is trained on the Turku NER data.\r\n  - The Hungarian model is trained on a combination of the NYTK dataset and earlier business and criminal NER datasets.\r\n  - The Vietnamese model is trained on the VLSP 2018 data.\r\n  - Furthermore, the script for preparing the lang-uk NER data has been integrated (https://github.com/stanfordnlp/stanza/commit/c1f0bee1074997d9376adaec45dc00f813d00b38)\r\n\r\n- **Use new word vectors for Armenian, including better coverage for the new Western Armenian dataset**(https://github.com/stanfordnlp/stanza/pull/718/commits/d9e8301addc93450dc880b06cb665ad10d869242)\r\n\r\n- **Add copy mechanism in the seq2seq model**.  This fixes some unusual Spanish multi-word token expansion errors and potentially improves lemmatization performance. (https://github.com/stanfordnlp/stanza/pull/692 https://github.com/stanfordnlp/stanza/issues/684)\r\n\r\n- **Fix Spanish POS and depparse mishandling a leading `\u00bf` missing** (https://github.com/stanfordnlp/stanza/pull/699 https://github.com/stanfordnlp/stanza/issues/698)\r\n\r\n- **Fix tokenization breaking when a newline splits a Chinese token**(https://github.com/stanfordnlp/stanza/pull/632 https://github.com/stanfordnlp/stanza/issues/531)\r\n\r\n- **Fix tokenization of parentheses in Chinese**(https://github.com/stanfordnlp/stanza/commit/452d842ed596bb7807e604eeb2295fd4742b7e89)\r\n\r\n- **Fix various issues with characters not present in UD training data** such as ellipses characters or unicode apostrophe\r\n(https://github.com/stanfordnlp/stanza/pull/719/commits/db0555253f0a68c76cf50209387dd2ff37794197 https://github.com/stanfordnlp/stanza/pull/719/commits/f01a1420755e3e0d9f4d7c2895e0261e581f7413 https://github.com/stanfordnlp/stanza/pull/719/commits/85898c50f14daed75b96eed9cd6e9d6f86e2d197)\r\n\r\n- **Fix a variety of issues with Vietnamese tokenization** - remove language specific model improvement which got roughly 1% F1 but caused numerous hard-to-track issues (https://github.com/stanfordnlp/stanza/pull/719/commits/3ccb132e03ce28a9061ec17d2c0ae84cc2000548)\r\n\r\n- **Fix spaces in the Vietnamese words not being found in the embedding used for POS and depparse**(https://github.com/stanfordnlp/stanza/pull/719/commits/197212269bc33b66759855a5addb99d1f465e4f4)\r\n\r\n- **Include UD_English-GUMReddit in the GUM models**(https://github.com/stanfordnlp/stanza/pull/719/commits/9e6367cb9bdd635d579fd8d389cb4d5fa121c413)\r\n\r\n- **Add Pronouns & PUD to the mixed English models** (various data improvements made this more appealing)(https://github.com/stanfordnlp/stanza/pull/719/commits/f74bef7b2ed171bf9c027ae4dfd3a10272040a46)\r\n\r\n## Interface enhancements\r\n\r\n- **Add ability to pass a Document to the pipeline in pretokenized mode**(https://github.com/stanfordnlp/stanza/commit/f88cd8c2f84aedeaec34a11b4bc27573657a66e2 https://github.com/stanfordnlp/stanza/issues/696)\r\n\r\n- **Track comments when reading and writing conll files** (https://github.com/stanfordnlp/stanza/pull/676 originally from @danielhers in https://github.com/stanfordnlp/stanza/pull/155)\r\n\r\n- **Add a proxy parameter for downloads to pass through to the requests module** (https://github.com/stanfordnlp/stanza/pull/638)\r\n\r\n- **add sent_idx to tokens** (https://github.com/stanfordnlp/stanza/commit/ee6135c538e24ff37d08b86f34668ccb223c49e1)\r\n\r\n## Bugfixes\r\n\r\n- **Fix Windows encoding issues when reading conll documents** from @yanirmr (b40379eaf229e7ffc7580def57ee1fad46080261 https://github.com/stanfordnlp/stanza/pull/695)\r\n\r\n- **Fix tokenization breaking when second batch is exactly eval_length**(https://github.com/stanfordnlp/stanza/commit/726368644d7b1019825f915fabcfe1e4528e068e https://github.com/stanfordnlp/stanza/issues/634 https://github.com/stanfordnlp/stanza/issues/631)\r\n\r\n## Efficiency improvements\r\n\r\n- **Bulk process for tokenization** - greatly speeds up the use case of many small docs (https://github.com/stanfordnlp/stanza/pull/719/commits/5d2d39ec822c65cb5f60d547357ad8b821683e3c)\r\n\r\n- **Optimize MWT usage in pipeline & fix MWT bulk_process** (https://github.com/stanfordnlp/stanza/pull/642 https://github.com/stanfordnlp/stanza/pull/643 https://github.com/stanfordnlp/stanza/pull/644)\r\n\r\n## CoreNLP integration\r\n\r\n- **Add a UD Enhancer tool which interfaces with CoreNLP's generic enhancer** (https://github.com/stanfordnlp/stanza/pull/675)\r\n\r\n- **Add an interface to CoreNLP tokensregex using stanza tokenization** (https://github.com/stanfordnlp/stanza/pull/659)\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/39087456/reactions", "total_count": 45, "+1": 18, "-1": 0, "laugh": 4, "hooray": 8, "confused": 0, "heart": 8, "rocket": 4, "eyes": 3}}
{"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/29792569", "assets_url": "https://api.github.com/repos/stanfordnlp/stanza/releases/29792569/assets", "upload_url": "https://uploads.github.com/repos/stanfordnlp/stanza/releases/29792569/assets{?name,label}", "html_url": "https://github.com/stanfordnlp/stanza/releases/tag/v1.2.0", "id": 29792569, "author": {"login": "AngledLuffa", "id": 3411033, "node_id": "MDQ6VXNlcjM0MTEwMzM=", "avatar_url": "https://avatars.githubusercontent.com/u/3411033?v=4", "gravatar_id": "", "url": "https://api.github.com/users/AngledLuffa", "html_url": "https://github.com/AngledLuffa", "followers_url": "https://api.github.com/users/AngledLuffa/followers", "following_url": "https://api.github.com/users/AngledLuffa/following{/other_user}", "gists_url": "https://api.github.com/users/AngledLuffa/gists{/gist_id}", "starred_url": "https://api.github.com/users/AngledLuffa/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/AngledLuffa/subscriptions", "organizations_url": "https://api.github.com/users/AngledLuffa/orgs", "repos_url": "https://api.github.com/users/AngledLuffa/repos", "events_url": "https://api.github.com/users/AngledLuffa/events{/privacy}", "received_events_url": "https://api.github.com/users/AngledLuffa/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTI5NzkyNTY5", "tag_name": "v1.2.0", "target_commitish": "master", "name": "Stanza v1.2.0", "draft": false, "prerelease": false, "created_at": "2021-01-27T23:00:47Z", "published_at": "2021-01-29T20:05:25Z", "assets": [], "tarball_url": "https://api.github.com/repos/stanfordnlp/stanza/tarball/v1.2.0", "zipball_url": "https://api.github.com/repos/stanfordnlp/stanza/zipball/v1.2.0", "body": "# Overview\r\n\r\nAll models other than NER and Sentiment were retrained with the new UD 2.7 release.  Quite a few of them have data augmentation fixes for problems which arise in common use rather than when running an evaluation task. This release also features various enhancements, bug fixes, and performance improvements.\r\n\r\n## New features and enhancements\r\n\r\n- **Models trained on combined datasets in English and Italian** The default models for English are now a combination of EWT and GUM.  The default models for Italian now combine ISDT, VIT, Twittiro, PosTWITA, and a custom dataset including MWT tokens.\r\n\r\n- **NER Transfer Learning** Allows users to fine-tune all or part of the parameters of trained NER models on a new dataset for transfer learning (#351, thanks to @gawy for the contribution)\r\n\r\n- **Multi-document support** The Stanza `Pipeline` now supports multi-`Document` input! To process multiple documents without having to worry about document boundaries, simply pass a list of Stanza `Document` objects into the `Pipeline`. (https://github.com/stanfordnlp/stanza/issues/70 https://github.com/stanfordnlp/stanza/pull/577)\r\n\r\n- **Added API links from token to sentence** It's easier to access Stanza data objects from related ones. To access the sentence object  a token or a word, simply use `token.sent` or `word.sent`. (https://github.com/stanfordnlp/stanza/issues/533 https://github.com/stanfordnlp/stanza/pull/554)\r\n\r\n- **New external tokenizer for Thai with PyThaiNLP** Try it out with, for example, `stanza.Pipeline(lang='th', processors={'tokenize': 'pythainlp'}, package=None)`. (https://github.com/stanfordnlp/stanza/pull/567)\r\n\r\n- **Faster tokenization** We have improved how the data pipeline works internally to reduce redundant data wrangling, and significantly sped up the tokenization of long texts. If you have a really long line of text, you could experience up to 10x speedup or more without changing anything. (#522)\r\n\r\n- **Added a method for getting all the supported languages from the resources file** Wondering what languages Stanza supports and want to determine it programmatically? Wonder no more! Try `stanza.resources.common.list_available_languages()`. (https://github.com/stanfordnlp/stanza/issues/511 https://github.com/stanfordnlp/stanza/commit/fa52f8562f20ab56807b35ba204d6f9ca60b47ab)\r\n\r\n- **Load mwt automagically if a model needs it** Multi-word token expansion is one of the most common things to miss from your `Pipeline` instantiation, and remembering to include it is a pain -- until now. (https://github.com/stanfordnlp/stanza/pull/516 https://github.com/stanfordnlp/stanza/issues/515  and many others)\r\n\r\n- **Vietnamese sentiment model based on VSFC** This is now part of the default language package for Vietnamese that you get from `stanza.download(\"vi\")`. Enjoy!\r\n\r\n- **More informative errors for missing models** Stanza now throws more helpful exceptions with informative exception messages when you are missing models (https://github.com/stanfordnlp/stanza/pull/437 https://github.com/stanfordnlp/stanza/issues/430 ... https://github.com/stanfordnlp/stanza/issues/324 https://github.com/stanfordnlp/stanza/pull/438 ... https://github.com/stanfordnlp/stanza/issues/529 https://github.com/stanfordnlp/stanza/commit/953966539c955951d01e3d6b4561fab02a1f546c ... https://github.com/stanfordnlp/stanza/issues/575 https://github.com/stanfordnlp/stanza/pull/578)\r\n\r\n## Bugfixes\r\n\r\n- **Fixed NER documentation for German** to correctly point to the GermEval 2014 model for download. (https://github.com/stanfordnlp/stanza/commit/4ee9f12be5911bb600d2f162b1684cb4686c391e https://github.com/stanfordnlp/stanza/issues/559)\r\n\r\n- **External tokenization library integration respects `no_ssplit`** so you can enjoy using them without messing up your preferred sentence segmentation just like Stanza tokenizers. (https://github.com/stanfordnlp/stanza/issues/523 https://github.com/stanfordnlp/stanza/pull/556)\r\n\r\n- **Telugu lemmatizer and tokenizer improvements** Telugu models set to use identity lemmatizer by default, and the tokenizer is retrained to separate sentence final punctuation (https://github.com/stanfordnlp/stanza/issues/524 https://github.com/stanfordnlp/stanza/commit/ba0aec30e6e691155bc0226e4cdbb829cb3489df)\r\n\r\n- **Spanish model would not tokenize foo,bar** Now fixed (https://github.com/stanfordnlp/stanza/issues/528 https://github.com/stanfordnlp/stanza/commit/123d5029303a04185c5574b76fbed27cb992cadd)\r\n\r\n- **Arabic model would not tokenize `asdf .`** Now fixed (https://github.com/stanfordnlp/stanza/issues/545 https://github.com/stanfordnlp/stanza/commit/03b7ceacf73870b2a15b46479677f4914ea48745)\r\n\r\n- **Various tokenization models would split URLs and/or emails** Now URLs and emails are robustly handled with regexes. (https://github.com/stanfordnlp/stanza/issues/539 https://github.com/stanfordnlp/stanza/pull/588)\r\n\r\n- **Various parser and pos models would deterministically label \"punct\" for the final word** Resolved via data augmentation (https://github.com/stanfordnlp/stanza/issues/471 https://github.com/stanfordnlp/stanza/issues/488 https://github.com/stanfordnlp/stanza/pull/491)\r\n\r\n- **Norwegian tokenizers retrained to separate final punct** The fix is an upstream data fix (https://github.com/stanfordnlp/stanza/issues/305 https://github.com/UniversalDependencies/UD_Norwegian-Bokmaal/pull/5)\r\n\r\n- **Bugfix for conll eval** Fix the error in data conversion from python object of Document to CoNLL format. (https://github.com/stanfordnlp/stanza/pull/484 https://github.com/stanfordnlp/stanza/issues/483, thanks @m0re4u )\r\n\r\n- **Less randomness in sentiment results** Fixes prediction fluctuation in sentiment prediction. (https://github.com/stanfordnlp/stanza/issues/458 https://github.com/stanfordnlp/stanza/commit/274474c3b0e4155ab6e221146ac347ca433f81a6)\r\n\r\n- **Bugfix which should make it easier to use in jupyter / colab** This fixes the issue where jupyter notebooks (and by extension colab) don't like it when you use sys.stderr as the stderr of popen (https://github.com/stanfordnlp/stanza/pull/434 https://github.com/stanfordnlp/stanza/issues/431)\r\n\r\n- **Misc fixes for training, concurrency, and edge cases in basic Pipeline usage**\r\n  - **Fix for mwt training** (https://github.com/stanfordnlp/stanza/pull/446)\r\n  - **Fix for race condition in seq2seq models** (https://github.com/stanfordnlp/stanza/pull/463 https://github.com/stanfordnlp/stanza/issues/462)\r\n  - **Fix for race condition in CRF** (https://github.com/stanfordnlp/stanza/pull/566 https://github.com/stanfordnlp/stanza/issues/561)\r\n  - **Fix for empty text in pipeline** (https://github.com/stanfordnlp/stanza/pull/475 https://github.com/stanfordnlp/stanza/issues/474)\r\n  - **Fix for resources not freed when downloading** (https://github.com/stanfordnlp/stanza/issues/502 https://github.com/stanfordnlp/stanza/pull/503)\r\n  - **Fix for vietnamese pipeline not working** (https://github.com/stanfordnlp/stanza/issues/531 https://github.com/stanfordnlp/stanza/pull/535)\r\n\r\n## BREAKING CHANGES\r\n\r\n- **Renamed `stanza.models.tokenize` -> `stanza.models.tokenization`** https://github.com/stanfordnlp/stanza/pull/452  This stops the tokenize directory shadowing a built in library"}
{"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/29594327", "assets_url": "https://api.github.com/repos/stanfordnlp/stanza/releases/29594327/assets", "upload_url": "https://uploads.github.com/repos/stanfordnlp/stanza/releases/29594327/assets{?name,label}", "html_url": "https://github.com/stanfordnlp/stanza/releases/tag/v1.1.1", "id": 29594327, "author": {"login": "J38", "id": 13620509, "node_id": "MDQ6VXNlcjEzNjIwNTA5", "avatar_url": "https://avatars.githubusercontent.com/u/13620509?v=4", "gravatar_id": "", "url": "https://api.github.com/users/J38", "html_url": "https://github.com/J38", "followers_url": "https://api.github.com/users/J38/followers", "following_url": "https://api.github.com/users/J38/following{/other_user}", "gists_url": "https://api.github.com/users/J38/gists{/gist_id}", "starred_url": "https://api.github.com/users/J38/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/J38/subscriptions", "organizations_url": "https://api.github.com/users/J38/orgs", "repos_url": "https://api.github.com/users/J38/repos", "events_url": "https://api.github.com/users/J38/events{/privacy}", "received_events_url": "https://api.github.com/users/J38/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTI5NTk0MzI3", "tag_name": "v1.1.1", "target_commitish": "master", "name": "Stanza v1.1.1", "draft": false, "prerelease": false, "created_at": "2020-08-13T06:05:37Z", "published_at": "2020-08-13T06:26:20Z", "assets": [], "tarball_url": "https://api.github.com/repos/stanfordnlp/stanza/tarball/v1.1.1", "zipball_url": "https://api.github.com/repos/stanfordnlp/stanza/zipball/v1.1.1", "body": "## Overview\r\n\r\nThis release features support for extending the capability of the Stanza pipeline with customized processors, a new sentiment analysis tool, improvements to the `CoreNLPClient` functionality, new models for a few languages (including Thai, which is supported for the first time in Stanza), new biomedical and clinical English packages, alternative servers for downloading resource files, and various improvements and bugfixes.\r\n\r\n## New Features and Enhancements\r\n\r\n- **New Sentiment Analysis Models for English, German, Chinese**: The default Stanza pipelines for English, German and Chinese now include sentiment analysis models. The released models are based on a convolutional neural network architecture, and predict three-way sentiment labels (negative/neutral/positive). For more information and details on the datasets used to train these models and their performance, please visit the Stanza website.\r\n\r\n- **New Biomedical and Clinical English Model Packages**: Stanza now features syntactic analysis and named entity recognition functionality for English biomedical literature text and clinical notes. These newly introduced packages include: 2 individual biomedical syntactic analysis pipelines, 8 biomedical NER models, 1 clinical syntactic pipelines and 2 clinical NER models. For detailed information on how to download and use these pipelines, please visit [Stanza's biomedical models page](https://stanfordnlp.github.io/stanza/biomed.html).\r\n\r\n- **Support for Adding User Customized Processors via Python Decorators**: Stanza now supports adding customized processors or processor variants (i.e., an alternative of existing processors) into existing pipelines. The name and implementation of the added customized processors or processor variants can be specified via `@register_processor` or `@register_processor_variant` decorators. See Stanza website for more information and examples (see [custom Processors](https://stanfordnlp.github.io/stanza/pipeline.html#building-your-own-processors-and-using-them-in-the-neural-pipeline) and [Processor variants](https://stanfordnlp.github.io/stanza/pipeline.html#processor-variants)). (PR https://github.com/stanfordnlp/stanza/pull/322)\r\n\r\n- **Support for Editable Properties For Data Objects**: We have made it easier to extend the functionality of the Stanza neural pipeline by adding new annotations to Stanza's data objects (e.g., `Document`, `Sentence`, `Token`, etc). Aside from the annotation they already support, additional annotation can be easily attached through `data_object.add_property()`. See [our documentation](https://stanfordnlp.github.io/stanza/data_objects.html#adding-new-properties-to-stanza-data-objects) for more information and examples. (PR https://github.com/stanfordnlp/stanza/pull/323)\r\n\r\n- **Support for Automated CoreNLP Installation and CoreNLP Model Download**: CoreNLP can now be easily downloaded in Stanza with `stanza.install_corenlp(dir='path/to/corenlp/installation')`; CoreNLP models can now be downloaded with `stanza.download_corenlp_models(model='english', version='4.1.0', dir='path/to/corenlp/installation')`. For more details please see the Stanza website. (PR https://github.com/stanfordnlp/stanza/pull/363)\r\n\r\n- **Japanese Pipeline Supports SudachiPy as External Tokenizer**: You can now use the [SudachiPy library](https://github.com/WorksApplications/SudachiPy) as tokenizer in a Stanza Japanese pipeline. Turn on this when building a pipeline with `nlp = stanza.Pipeline('ja', processors={'tokenize': 'sudachipy'}`. Note that this will require a separate installation of the SudachiPy library via pip. (PR https://github.com/stanfordnlp/stanza/pull/365)\r\n\r\n- **New Alternative Server for Stable Download of Resource Files**: Users in certain areas of the world that do not have stable access to GitHub servers can now download models from alternative Stanford server by specifying a new `resources_url` argument. For example, `stanza.download(lang='en', resources_url='stanford')` will now download the resource file and English pipeline from Stanford servers. (Issue https://github.com/stanfordnlp/stanza/issues/331, PR https://github.com/stanfordnlp/stanza/pull/356)\r\n\r\n- **`CoreNLPClient` Supports New Multiprocessing-friendly Mechanism to Start the CoreNLP Server**: The `CoreNLPClient` now supports a new `Enum` values with better semantics for its `start_server` argument for finer-grained control over how the server is launched, including a new option called `StartServer.TRY_START` that launches the CoreNLP Server if one isn't running already, but doesn't fail if one has already been launched. This option makes it easier for `CoreNLPClient` to be used in a multiprocessing environment. Boolean values are still supported for backward compatibility, but we recommend `StartServer.FORCE_START` and `StartSerer.DONT_START` for better readability. (PR https://github.com/stanfordnlp/stanza/pull/302)\r\n\r\n- **New Semgrex Interface in CoreNLP Client for Dependency Parses of Arbitrary Languages**: Stanford CoreNLP has a module which allows searches over dependency graphs using a regex-like language.  Previously, this was only usable for languages which CoreNLP already supported dependency trees.  This release expands it to dependency graphs for any language.  (Issue https://github.com/stanfordnlp/stanza/issues/399, PR https://github.com/stanfordnlp/stanza/pull/392)\r\n\r\n- **New Tokenizer for Thai Language**: The available UD data for Thai is quite small.  The authors of [pythainlp](https://github.com/PyThaiNLP/pythainlp) helped provide us two tokenization datasets, Orchid and Inter-BEST.  Future work will include POS, NER, and Sentiment.  (Issue https://github.com/stanfordnlp/stanza/issues/148)\r\n\r\n- **Support for Serialization of Document Objects**: Now you can serialize and deserialize the entire document by running `serialized_string = doc.to_serialized()` and `doc = Document.from_serialized(serialized_string)`. The serialized string can be decoded into Python objects by running `objs = pickle.loads(serialized_string)`. (Issue https://github.com/stanfordnlp/stanza/issues/361, PR https://github.com/stanfordnlp/stanza/pull/366)\r\n\r\n- **Improved Tokenization Speed**: Previously, the tokenizer was the slowest member of the neural pipeline, several times slower than any of the other processors.  This release brings it in line with the others.  The speedup is from improving the text processing before the data is passed to the GPU.  (Relevant commits: https://github.com/stanfordnlp/stanza/commit/546ed13563c3530b414d64b5a815c0919ab0513a, https://github.com/stanfordnlp/stanza/commit/8e2076c6a0bc8890a54d9ed6931817b1536ae33c, https://github.com/stanfordnlp/stanza/commit/7f5be823a587c6d1bec63d47cd22818c838901e7, etc.)\r\n\r\n- **User provided Ukrainian NER model**: We now have a [model](https://github.com/gawy/stanza-lang-uk/releases/tag/v0.9) built from the [lang-uk NER dataset](https://github.com/lang-uk/ner-uk), provided by a user for redistribution.\r\n\r\n## Breaking Interface Changes\r\n\r\n- **Token.id is Tuple and Word.id is Integer**: The `id` attribute for a token will now return a tuple of integers to represent the indices of the token (or a singleton tuple in the case of a single-word token), and the `id` for a word will now return an integer to represent the word index. Previously both attributes are encoded as strings and requires manual conversion for downstream processing. This change brings more convenient handling of these attributes. (Issue: https://github.com/stanfordnlp/stanza/issues/211, PR: https://github.com/stanfordnlp/stanza/pull/357)\r\n\r\n- **Changed Default Pipeline Packages for Several Languages for Improved Robustness**: Languages that have changed default packages include: Polish (default is now `PDB` model, from previous `LFG`, https://github.com/stanfordnlp/stanza/issues/220), Korean (default is now `GSD`, from previous `Kaist`, https://github.com/stanfordnlp/stanza/issues/276), Lithuanian (default is now `ALKSNIS`, from previous `HSE`, https://github.com/stanfordnlp/stanza/issues/415).\r\n\r\n- **CoreNLP 4.1.0 is required**: `CoreNLPClient` requires CoreNLP 4.1.0 or a later version. The client expects recent modifications that were made to the CoreNLP server.\r\n\r\n- **Properties Cache removed from CoreNLP client**: The properties_cache has been removed from `CoreNLPClient` and the `CoreNLPClient's` `annotate()` method no longer has a `properties_key` argument. Python dictionaries with custom request properties should be directly supplied to `annotate()` via the `properties` argument.\r\n\r\n## Bugfixes and Other Improvements\r\n\r\n- **Fixed Logging Behavior**: This is mainly for fixing the issue that Stanza will override the global logging setting in Python and influence downstream logging behaviors. (Issue https://github.com/stanfordnlp/stanza/issues/278, PR https://github.com/stanfordnlp/stanza/pull/290)\r\n\r\n- **Compatibility Fix for PyTorch v1.6.0**: We've updated several processors to adapt to new API changes in PyTorch v1.6.0. (Issues https://github.com/stanfordnlp/stanza/issues/412 https://github.com/stanfordnlp/stanza/issues/417, PR https://github.com/stanfordnlp/stanza/pull/406)\r\n\r\n- **Improved Batching for Long Sentences in Dependency Parser**: This is mainly for fixing an issue where long sentences will cause an out of GPU memory issue in the dependency parser. (Issue https://github.com/stanfordnlp/stanza/issues/387)\r\n\r\n- **Improved neural tokenizer robustness to whitespaces**: the neural tokenizer is now more robust to the presence of multiple consecutive whitespace characters (PR https://github.com/stanfordnlp/stanza/pull/380)\r\n\r\n- **Resolved properties issue when switching languages with requests to CoreNLP server**: An issue with default properties has been resolved. Users can now switch between CoreNLP supported languages with and get expected properties for each language by default."}
{"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/25908143", "assets_url": "https://api.github.com/repos/stanfordnlp/stanza/releases/25908143/assets", "upload_url": "https://uploads.github.com/repos/stanfordnlp/stanza/releases/25908143/assets{?name,label}", "html_url": "https://github.com/stanfordnlp/stanza/releases/tag/v1.0.1", "id": 25908143, "author": {"login": "yuhaozhang", "id": 4032415, "node_id": "MDQ6VXNlcjQwMzI0MTU=", "avatar_url": "https://avatars.githubusercontent.com/u/4032415?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yuhaozhang", "html_url": "https://github.com/yuhaozhang", "followers_url": "https://api.github.com/users/yuhaozhang/followers", "following_url": "https://api.github.com/users/yuhaozhang/following{/other_user}", "gists_url": "https://api.github.com/users/yuhaozhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/yuhaozhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yuhaozhang/subscriptions", "organizations_url": "https://api.github.com/users/yuhaozhang/orgs", "repos_url": "https://api.github.com/users/yuhaozhang/repos", "events_url": "https://api.github.com/users/yuhaozhang/events{/privacy}", "received_events_url": "https://api.github.com/users/yuhaozhang/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTI1OTA4MTQz", "tag_name": "v1.0.1", "target_commitish": "master", "name": "Stanza v1.0.1", "draft": false, "prerelease": false, "created_at": "2020-04-27T06:22:36Z", "published_at": "2020-04-27T07:21:58Z", "assets": [], "tarball_url": "https://api.github.com/repos/stanfordnlp/stanza/tarball/v1.0.1", "zipball_url": "https://api.github.com/repos/stanfordnlp/stanza/zipball/v1.0.1", "body": "## Overview\r\n\r\nThis is a maintenance release of Stanza. It features new support for `jieba` as Chinese tokenizer, faster lemmatizer implementation, improved compatibility with CoreNLP v4.0.0, and many more!\r\n\r\n## Enhancements\r\n\r\n- **Supporting `jieba` library as Chinese tokenizer**. The Stanza (simplified and traditional) Chinese pipelines now support using the `jieba` Chinese word segmentation library as tokenizer. Turn on this feature in a pipeline with: `nlp = stanza.Pipeline('zh', processors={'tokenize': 'jieba'}`, or by specifying argument `tokenize_with_jieba=True`.\r\n\r\n- **Setting resource directory with environment variable**. You can now override the default model location `$HOME/stanza_resources` by setting an environmental variable `STANZA_RESOURCES_DIR` (https://github.com/stanfordnlp/stanza/issues/227). The new directory will then be used to store and look up model files. Thanks to @dhpollack for implementing this feature.\r\n\r\n- **Faster lemmatizer implementation.** The lemmatizer implementation has been improved to be about 3x faster on CPU and 5x faster on GPU (https://github.com/stanfordnlp/stanza/issues/249). Thanks to @mahdiman for identifying the original issue.\r\n\r\n- **Improved compatibility with CoreNLP 4.0.0**. The client is now fully compatible with the latest [v4.0.0 release of the CoreNLP package](https://stanfordnlp.github.io/CoreNLP/).\r\n\r\n## Bugfixes\r\n\r\n- **Correct character offsets in NER outputs from pre-tokenized text**. We fixed an issue where the NER outputs from pre-tokenized text may be off-by-one (https://github.com/stanfordnlp/stanza/issues/229). Thanks to @RyanElliott10 for reporting the issue.\r\n\r\n- **Correct Vietnamese tokenization on sentences beginning with punctuation**. We fixed an issue where the Vietnamese tokenizer may throw an `AssertionError` on sentences that begin with a punctuation (https://github.com/stanfordnlp/stanza/issues/217). Thanks to @aryamccarthy for reporting this issue.\r\n\r\n- **Correct pytorch version requirement**. Stanza is now asking for `pytorch>=1.3.0` to avoid a runtime error raised by pytorch ((https://github.com/stanfordnlp/stanza/issues/231)). Thanks to @Vodkazy for reporting this.\r\n\r\n## Known Model Issues & Solutions\r\n\r\n- **Default Korean Kaist tokenizer failing on punctuation.** The default Korean Kaist model is reported to have issues with separating punctuations during tokenization (https://github.com/stanfordnlp/stanza/issues/276). Switching to the Korean `GSD` model may solve this issue.\r\n\r\n- **Default Polish LFG POS tagger incorrectly labeling last word in sentence as `PUNCT`**. The default Polish model trained on the `LFG` treebank may incorrectly tag the last word in a sentence as `PUNCT` (https://github.com/stanfordnlp/stanza/issues/220). This issue may be solved by switching to the Polish `PDB` model.\r\n\r\n"}
{"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/25940010", "assets_url": "https://api.github.com/repos/stanfordnlp/stanza/releases/25940010/assets", "upload_url": "https://uploads.github.com/repos/stanfordnlp/stanza/releases/25940010/assets{?name,label}", "html_url": "https://github.com/stanfordnlp/stanza/releases/tag/1.0.1", "id": 25940010, "author": {"login": "yuhaozhang", "id": 4032415, "node_id": "MDQ6VXNlcjQwMzI0MTU=", "avatar_url": "https://avatars.githubusercontent.com/u/4032415?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yuhaozhang", "html_url": "https://github.com/yuhaozhang", "followers_url": "https://api.github.com/users/yuhaozhang/followers", "following_url": "https://api.github.com/users/yuhaozhang/following{/other_user}", "gists_url": "https://api.github.com/users/yuhaozhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/yuhaozhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yuhaozhang/subscriptions", "organizations_url": "https://api.github.com/users/yuhaozhang/orgs", "repos_url": "https://api.github.com/users/yuhaozhang/repos", "events_url": "https://api.github.com/users/yuhaozhang/events{/privacy}", "received_events_url": "https://api.github.com/users/yuhaozhang/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTI1OTQwMDEw", "tag_name": "1.0.1", "target_commitish": "master", "name": "Stanza v1.0.1", "draft": false, "prerelease": false, "created_at": "2020-04-27T06:22:36Z", "published_at": "2020-04-27T21:43:25Z", "assets": [], "tarball_url": "https://api.github.com/repos/stanfordnlp/stanza/tarball/1.0.1", "zipball_url": "https://api.github.com/repos/stanfordnlp/stanza/zipball/1.0.1", "body": "## Overview\r\n\r\nThis is a maintenance release of Stanza. It features new support for `jieba` as Chinese tokenizer, faster lemmatizer implementation, improved compatibility with CoreNLP v4.0.0, and many more!\r\n\r\n## Enhancements\r\n\r\n- **Supporting `jieba` library as Chinese tokenizer**. The Stanza (simplified and traditional) Chinese pipelines now support using the `jieba` Chinese word segmentation library as tokenizer. Turn on this feature in a pipeline with: `nlp = stanza.Pipeline('zh', processors={'tokenize': 'jieba'}`, or by specifying argument `tokenize_with_jieba=True`.\r\n\r\n- **Setting resource directory with environment variable**. You can now override the default model location `$HOME/stanza_resources` by setting an environmental variable `STANZA_RESOURCES_DIR` (https://github.com/stanfordnlp/stanza/issues/227). The new directory will then be used to store and look up model files. Thanks to @dhpollack for implementing this feature.\r\n\r\n- **Faster lemmatizer implementation.** The lemmatizer implementation has been improved to be about 3x faster on CPU and 5x faster on GPU (https://github.com/stanfordnlp/stanza/issues/249). Thanks to @mahdiman for identifying the original issue.\r\n\r\n- **Improved compatibility with CoreNLP 4.0.0**. The client is now fully compatible with the latest [v4.0.0 release of the CoreNLP package](https://stanfordnlp.github.io/CoreNLP/).\r\n\r\n## Bugfixes\r\n\r\n- **Correct character offsets in NER outputs from pre-tokenized text**. We fixed an issue where the NER outputs from pre-tokenized text may be off-by-one (https://github.com/stanfordnlp/stanza/issues/229). Thanks to @RyanElliott10 for reporting the issue.\r\n\r\n- **Correct Vietnamese tokenization on sentences beginning with punctuation**. We fixed an issue where the Vietnamese tokenizer may throw an `AssertionError` on sentences that begin with a punctuation (https://github.com/stanfordnlp/stanza/issues/217). Thanks to @aryamccarthy for reporting this issue.\r\n\r\n- **Correct pytorch version requirement**. Stanza is now asking for `pytorch>=1.3.0` to avoid a runtime error raised by pytorch ((https://github.com/stanfordnlp/stanza/issues/231)). Thanks to @Vodkazy for reporting this.\r\n\r\n## Known Model Issues & Solutions\r\n\r\n- **Default Korean Kaist tokenizer failing on punctuation.** The default Korean Kaist model is reported to have issues with separating punctuations during tokenization (https://github.com/stanfordnlp/stanza/issues/276). Switching to the Korean `GSD` model may solve this issue.\r\n\r\n- **Default Polish LFG POS tagger incorrectly labeling last word in sentence as `PUNCT`**. The default Polish model trained on the `LFG` treebank may incorrectly tag the last word in a sentence as `PUNCT` (https://github.com/stanfordnlp/stanza/issues/220). This issue may be solved by switching to the Polish `PDB` model.\r\n\r\n"}
{"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/24604222", "assets_url": "https://api.github.com/repos/stanfordnlp/stanza/releases/24604222/assets", "upload_url": "https://uploads.github.com/repos/stanfordnlp/stanza/releases/24604222/assets{?name,label}", "html_url": "https://github.com/stanfordnlp/stanza/releases/tag/v1.0.0", "id": 24604222, "author": {"login": "qipeng", "id": 1572802, "node_id": "MDQ6VXNlcjE1NzI4MDI=", "avatar_url": "https://avatars.githubusercontent.com/u/1572802?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qipeng", "html_url": "https://github.com/qipeng", "followers_url": "https://api.github.com/users/qipeng/followers", "following_url": "https://api.github.com/users/qipeng/following{/other_user}", "gists_url": "https://api.github.com/users/qipeng/gists{/gist_id}", "starred_url": "https://api.github.com/users/qipeng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qipeng/subscriptions", "organizations_url": "https://api.github.com/users/qipeng/orgs", "repos_url": "https://api.github.com/users/qipeng/repos", "events_url": "https://api.github.com/users/qipeng/events{/privacy}", "received_events_url": "https://api.github.com/users/qipeng/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTI0NjA0MjIy", "tag_name": "v1.0.0", "target_commitish": "master", "name": "Stanza v1.0.0", "draft": false, "prerelease": false, "created_at": "2020-03-17T02:05:43Z", "published_at": "2020-03-17T17:13:53Z", "assets": [], "tarball_url": "https://api.github.com/repos/stanfordnlp/stanza/tarball/v1.0.0", "zipball_url": "https://api.github.com/repos/stanfordnlp/stanza/zipball/v1.0.0", "body": "## Overview\r\nThis is the first major release of Stanza (previously known as [StanfordNLP](https://github.com/stanfordnlp/stanfordnlp/)), a software package to process many human languages. The main features of this release are\r\n* **Multi-lingual named entity recognition support**. Stanza supports named entity recognition in 8 languages (and 12 datasets): Arabic, Chinese, Dutch, English, French, German, Russian, and Spanish. The most comprehensive NER models in each language is now part of the default model download of that model, along with other models trained on the largest dataset available.\r\n* **Accurate neural network models**. Stanza features highly accurate data-driven neural network models for a wide collection of natural language processing tasks, including tokenization, sentence segmentation, part-of-speech tagging, morphological feature tagging, dependency parsing, and named entity recognition.\r\n* **State-of-the-art pretrained models freely available**. Stanza features a few hundred pretrained models for 60+ languages, all freely availble and easily downloadable from native Python code. Most of these models achieve state-of-the-art (or competitive) performance on these tasks.\r\n* **Expanded language support**. Stanza now supports more than 60 human languages, representing a wide-range of language families.\r\n* **Easy-to-use native Python interface**. We've improved the usability of the interface to maximize transparency. Now intermediate processing results are more easily viewed and accessed as native Python objects.\r\n* **Anaconda support**. Stanza now officially supports installation from Anaconda. You can install Stanza through Stanford NLP Group's Anaconda channel `conda install -c stanfordnlp stanza`.\r\n* **Improved documentation**. We have improved [our documentation](https://stanfordnlp.github.io/stanza/) to include a comprehensive coverage of the basic and advanced functionalities supported by Stanza.\r\n* **Improved CoreNLP support in Python**. We have improved the robustness and efficiency of the `CoreNLPClient` to access the Java CoreNLP software from Python code. It is also forward compatible with the next major release of CoreNLP.\r\n## Enhancements and Bugfixes\r\nThis release also contains many enhancements and bugfixes:\r\n* [Enhancement] Improved lemmatization support with proper conditioning on POS tags (#143). Thanks to @nljubesi for the report!\r\n* [Enhancement] Get the text corresponding to sentences in the document. Access it through `sentence.text`. (#80)\r\n* [Enhancement] Improved logging. Stanza now uses Python's `logging` for all procedual logging, which can be controlled globally either through `logging_level` or a `verbose` shortcut. See [this page](https://stanfordnlp.github.io/stanza/pipeline.html#pipeline) for more information. (#81)\r\n* [Enhancement] Allow the user to use the Stanza tokenizer with their own sentence split, which might be useful for applications like machine translation. Simply set `tokenize_no_ssplit` to `True` at pipeline instantiation. (#108)\r\n* [Enhancement] Support running the dependency parser only given tokenized,  sentence segmented, and POS/morphological feature tagged data. Simply set `depparse_pretagged` to `True` at pipeline instantiation. (#141) Thanks @mrapacz for the contribution!\r\n* [Enhancement] Added spaCy as an option for tokenizing (and sentence segmenting) English text for efficiency. See this [documentation page](https://stanfordnlp.github.io/stanza/tokenize.html#use-spacy-for-fast-tokenization-and-sentence-segmentation) for a quick example.\r\n* [Enhancement] Add character offsets to tokens, sentences, and spans.\r\n* [Bugfix] Correctly decide whether to load pretrained embedding files given training flags. (#120)\r\n* [Bugfix] Google proto buffers reporting errors for long input when using the `CoreNLPClient`. (#154)\r\n* [Bugfix] Remove deprecation warnings from newer versions of PyTorch. (#162)\r\n## Breaking Changes\r\nNote that if your code was developed on a previous version of the package, there are potentially many breaking changes in this release. The most notable changes are in the `Document` objects, which contain all the annotations for the raw text or document fed into the Stanza pipeline. The underlying implementation of `Document` and all related data objects have broken away from using the CoNLL-U format as its internal representation for more flexibility and efficiency accessing their attributes, although it is still compatible with CoNLL-U to maintain ease of conversion between the two. Moreover, many properties have been renamed for clarity and sometimes aliased for ease of access. Please see our documentation page about these [data objects](https://stanfordnlp.github.io/stanza/data_objects.html) for more information."}
{"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/17403050", "assets_url": "https://api.github.com/repos/stanfordnlp/stanza/releases/17403050/assets", "upload_url": "https://uploads.github.com/repos/stanfordnlp/stanza/releases/17403050/assets{?name,label}", "html_url": "https://github.com/stanfordnlp/stanza/releases/tag/v0.2.0", "id": 17403050, "author": {"login": "J38", "id": 13620509, "node_id": "MDQ6VXNlcjEzNjIwNTA5", "avatar_url": "https://avatars.githubusercontent.com/u/13620509?v=4", "gravatar_id": "", "url": "https://api.github.com/users/J38", "html_url": "https://github.com/J38", "followers_url": "https://api.github.com/users/J38/followers", "following_url": "https://api.github.com/users/J38/following{/other_user}", "gists_url": "https://api.github.com/users/J38/gists{/gist_id}", "starred_url": "https://api.github.com/users/J38/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/J38/subscriptions", "organizations_url": "https://api.github.com/users/J38/orgs", "repos_url": "https://api.github.com/users/J38/repos", "events_url": "https://api.github.com/users/J38/events{/privacy}", "received_events_url": "https://api.github.com/users/J38/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTE3NDAzMDUw", "tag_name": "v0.2.0", "target_commitish": "master", "name": "v0.2.0", "draft": false, "prerelease": false, "created_at": "2019-05-16T07:35:44Z", "published_at": "2019-05-16T17:31:43Z", "assets": [], "tarball_url": "https://api.github.com/repos/stanfordnlp/stanza/tarball/v0.2.0", "zipball_url": "https://api.github.com/repos/stanfordnlp/stanza/zipball/v0.2.0", "body": "This release features major improvements on memory efficiency and speed of the neural network pipeline in stanfordnlp and various bugfixes. These features include:\r\n\r\n- The downloadable pretrained neural network models are now substantially smaller in size (due to the use of smaller pretrained vocabularies) with comparable performance. Notably, the default English model is now ~9x smaller in size, German ~11x, French ~6x and  Chinese ~4x. As a result, memory efficiency of the neural pipelines for most languages are substantially improved.\r\n\r\n- Substantial speedup of the neural lemmatizer via reduced neural sequence-to-sequence operations.\r\n\r\n- The neural network pipeline can now take in a Python list of strings representing pre-tokenized text. (https://github.com/stanfordnlp/stanfordnlp/issues/58)\r\n\r\n- A requirements checking framework is now added in the neural pipeline, ensuring the proper processors are specified for a given pipeline configuration. The pipeline will now raise an exception when a requirement is not satisfied. (https://github.com/stanfordnlp/stanfordnlp/issues/42)\r\n\r\n- Bugfix related to alignment between tokens and words post the multi-word expansion processor. (https://github.com/stanfordnlp/stanfordnlp/issues/71)\r\n\r\n- More options are added for customizing the Stanford CoreNLP server at start time, including specifying properties for the default pipeline, and setting all server options such as username/password. For more details on different options, please checkout the [client documentation page](https://stanfordnlp.github.io/stanfordnlp/corenlp_client.html#customizing-properties-for-server-start-and-requests).\r\n\r\n- `CoreNLPClient` instance can now be created with CoreNLP default language properties as:\r\n```python\r\nclient = CoreNLPClient(properties='chinese')\r\n```\r\n\r\n- Alternatively, a properties file can now be used during the creation of a `CoreNLPClient`:\r\n```python\r\nclient = CoreNLPClient(properties='/path/to/corenlp.props')\r\n```\r\n\r\n- All specified CoreNLP annotators are now preloaded by default when a `CoreNLPClient` instance is created. (https://github.com/stanfordnlp/stanfordnlp/issues/56)\r\n"}
{"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/15794254", "assets_url": "https://api.github.com/repos/stanfordnlp/stanza/releases/15794254/assets", "upload_url": "https://uploads.github.com/repos/stanfordnlp/stanza/releases/15794254/assets{?name,label}", "html_url": "https://github.com/stanfordnlp/stanza/releases/tag/v0.1.2", "id": 15794254, "author": {"login": "qipeng", "id": 1572802, "node_id": "MDQ6VXNlcjE1NzI4MDI=", "avatar_url": "https://avatars.githubusercontent.com/u/1572802?v=4", "gravatar_id": "", "url": "https://api.github.com/users/qipeng", "html_url": "https://github.com/qipeng", "followers_url": "https://api.github.com/users/qipeng/followers", "following_url": "https://api.github.com/users/qipeng/following{/other_user}", "gists_url": "https://api.github.com/users/qipeng/gists{/gist_id}", "starred_url": "https://api.github.com/users/qipeng/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/qipeng/subscriptions", "organizations_url": "https://api.github.com/users/qipeng/orgs", "repos_url": "https://api.github.com/users/qipeng/repos", "events_url": "https://api.github.com/users/qipeng/events{/privacy}", "received_events_url": "https://api.github.com/users/qipeng/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTE1Nzk0MjU0", "tag_name": "v0.1.2", "target_commitish": "master", "name": "v0.1.2", "draft": false, "prerelease": false, "created_at": "2019-02-26T22:39:54Z", "published_at": "2019-02-26T23:34:52Z", "assets": [], "tarball_url": "https://api.github.com/repos/stanfordnlp/stanza/tarball/v0.1.2", "zipball_url": "https://api.github.com/repos/stanfordnlp/stanza/zipball/v0.1.2", "body": "This is a maintenance release of stanfordnlp. This release features:\r\n\r\n* Allowing the tokenizer to treat the incoming document as pretokenized with space separated words in newline separated sentences. Set `tokenize_pretokenized` to `True` when building the pipeline to skip the neural tokenizer, and run all downstream components with your own tokenized text. (#24, #34)\r\n* Speedup in the POS/Feats tagger in evaluation (up to 2 orders of magnitude). (#18)\r\n* Various minor fixes and documentation improvements\r\n\r\nWe would also like to thank the following community members for their contribution:\r\nCode improvements: @lwolfsonkin \r\nDocumentation improvements: @0xflotus \r\nAnd thanks to everyone that raised issues and helped improve stanfordnlp!"}
{"url": "https://api.github.com/repos/stanfordnlp/stanza/releases/15277572", "assets_url": "https://api.github.com/repos/stanfordnlp/stanza/releases/15277572/assets", "upload_url": "https://uploads.github.com/repos/stanfordnlp/stanza/releases/15277572/assets{?name,label}", "html_url": "https://github.com/stanfordnlp/stanza/releases/tag/v0.1.0", "id": 15277572, "author": {"login": "yuhaozhang", "id": 4032415, "node_id": "MDQ6VXNlcjQwMzI0MTU=", "avatar_url": "https://avatars.githubusercontent.com/u/4032415?v=4", "gravatar_id": "", "url": "https://api.github.com/users/yuhaozhang", "html_url": "https://github.com/yuhaozhang", "followers_url": "https://api.github.com/users/yuhaozhang/followers", "following_url": "https://api.github.com/users/yuhaozhang/following{/other_user}", "gists_url": "https://api.github.com/users/yuhaozhang/gists{/gist_id}", "starred_url": "https://api.github.com/users/yuhaozhang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/yuhaozhang/subscriptions", "organizations_url": "https://api.github.com/users/yuhaozhang/orgs", "repos_url": "https://api.github.com/users/yuhaozhang/repos", "events_url": "https://api.github.com/users/yuhaozhang/events{/privacy}", "received_events_url": "https://api.github.com/users/yuhaozhang/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTE1Mjc3NTcy", "tag_name": "v0.1.0", "target_commitish": "master", "name": "v0.1.0", "draft": false, "prerelease": false, "created_at": "2019-01-30T00:55:00Z", "published_at": "2019-01-30T22:10:15Z", "assets": [], "tarball_url": "https://api.github.com/repos/stanfordnlp/stanza/tarball/v0.1.0", "zipball_url": "https://api.github.com/repos/stanfordnlp/stanza/zipball/v0.1.0", "body": "The initial release of StanfordNLP. StanfordNLP is the combination of the software package used by the Stanford team in the CoNLL 2018 Shared Task on Universal Dependency Parsing, and the group\u2019s official Python interface to the [Stanford CoreNLP software](https://stanfordnlp.github.io/CoreNLP). This package is built with highly accurate neural network components that enables efficient training and evaluation with your own annotated data. The modules are built on top of [PyTorch](https://pytorch.org/) (v1.0.0).\r\n\r\nStanfordNLP features:\r\n\r\n- Native Python implementation requiring minimal efforts to set up;\r\n- Full neural network pipeline for robust text analytics, including tokenization, multi-word token (MWT) expansion, lemmatization, part-of-speech (POS) and morphological features tagging and dependency parsing;\r\n- Pretrained neural models supporting 53 (human) languages featured in 73 treebanks;\r\n- A stable, officially maintained Python interface to CoreNLP."}
